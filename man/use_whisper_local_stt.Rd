% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/speech_to_text.R
\name{use_whisper_local_stt}
\alias{use_whisper_local_stt}
\title{Use Local Whisper Model for Speech-to-Text}
\usage{
use_whisper_local_stt(
  audio_file,
  language = "en",
  initial_prompt = "",
  model = "turbo",
  whisper_package = getOption("minutemaker_whisper_package", "openai-whisper")
)
}
\arguments{
\item{audio_file}{The path to the audio file to transcribe.}

\item{language}{The language of the input audio. Default is "en" for English.
If NULL, Whisper will attempt to detect the language.}

\item{initial_prompt}{Text to guide the model's style or continue a previous
segment.}

\item{model}{The Whisper model to use. Default is "turbo". Check
https://github.com/openai/whisper for other available models.}

\item{whisper_package}{The Python package to use for Whisper (default:
"openai-whisper").}
}
\value{
A list with the full transcript and the transcription by segments.
}
\description{
This function uses a local Whisper model via Python with reticulate to
transcribe audio. It can use the official OpenAI Whisper package or any
compatible Python package.
}
