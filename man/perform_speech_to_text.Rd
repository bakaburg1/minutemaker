% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/speech_to_text.R
\name{perform_speech_to_text}
\alias{perform_speech_to_text}
\title{Converts audio files to text transcripts using Whisper.}
\usage{
perform_speech_to_text(
  audio_path,
  output_dir = file.path(dirname(audio_path), "transcripts"),
  model,
  initial_prompt = "",
  overwrite = FALSE,
  language = "en",
  ...
)
}
\arguments{
\item{audio_path}{Path to one or more audio files or to a folder of audio
files. Tested with .mp3 and .wav files.}

\item{output_dir}{Path to output directory. If the directory doesn't exist,
it will be created in the same directory as the audio file and will be
named "transcripts".}

\item{model}{Name of the model to use. The models available in the package
are: "azure_whisper" (online API), "openai_whisper" (online API),
"whisper_ctranslate2" (offline local model). Users can provide their own
models.}

\item{initial_prompt}{Text to prepend to the beginning of each transcript.
This is useful for adding hard to parse words like acronyms.}

\item{overwrite}{If TRUE, will overwrite existing files. If FALSE, will skip
the transcription of audio files whose output already exist in the output
directory.}

\item{language}{Language in which the audio is spoken. If null, the model
will try to detect the language automatically.}

\item{...}{Additional arguments to pass to the model function.}
}
\value{
A data frame with the text and time of each segment.
}
\description{
Loops through audio files, runs a speech-to-text model on each, parses the
generated .srt files into a transcript data frame.
}
\details{
Users can provide your own model by writing a function with the following
name pattern: \verb{use_<model_name>_stt}. See the existing functions using the
::: operator for examples.
}
