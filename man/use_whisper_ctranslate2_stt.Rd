% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/speech_to_text.R
\name{use_whisper_ctranslate2_stt}
\alias{use_whisper_ctranslate2_stt}
\title{Use a local Whisper CTranslate2 model to transcribe audio}
\usage{
use_whisper_ctranslate2_stt(
  audio_file,
  initial_prompt,
  model_version = "large-v3",
  language = NULL,
  n_threads = parallel::detectCores()
)
}
\arguments{
\item{audio_file}{Path to the audio file to transcribe.}

\item{initial_prompt}{Initial prompt to use for the transcription.}

\item{model_version}{Version of the model to use. Can be one of "tiny", "medium",
"medium.en" "large-v1", "large-v2", "large-v3",}

\item{language}{Language of the recording. E.g. "en" for English, "es" for
Spanish, etc.}

\item{n_threads}{Number of CPU threads to use for the transcription.}
}
\value{
A list with the full transcript and the transcription by segments.
}
\description{
The function opens a terminal window and runs the command to transcribe the
audio file using the specified model. Opening a terminal window is necessary
to visualize the progress of the transcription. See
https://github.com/Softcatala/whisper-ctranslate2.
}
