% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/speech_to_text.R
\name{use_mlx_whisper_local_stt}
\alias{use_mlx_whisper_local_stt}
\title{Use MLX Whisper Local Model for Speech-to-Text (Mac OS only)}
\usage{
use_mlx_whisper_local_stt(
  audio_file,
  language = "en",
  initial_prompt = "",
  model = "mlx-community/distil-whisper-large-v3",
  whisper_package = getOption("minutemaker_whisper_package", "mlx_whisper")
)
}
\arguments{
\item{audio_file}{The path to the audio file to transcribe.}

\item{language}{The language of the input audio. Default is "en" for English.
If NULL, Whisper will attempt to detect the language.}

\item{initial_prompt}{Text to guide the model's style or continue a previous
segment.}

\item{model}{The MLX Whisper model to use. Default is
"mlx-community/whisper-large-v3-turbo".}

\item{whisper_package}{The Python package to use for MLX Whisper (default:
"mlx_whisper").}
}
\value{
A list with the full transcript and the transcription by segments.
}
\description{
This function uses a local MLX Whisper model via Python with reticulate to
transcribe audio. It is specifically designed to work with the MLX Whisper
package. MLX allows faster inference on Mac OS with Apple Silicon.
}
