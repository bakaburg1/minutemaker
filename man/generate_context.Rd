% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/context_generation.R
\name{generate_context}
\alias{generate_context}
\title{Generate meeting context from documentation materials}
\usage{
generate_context(
  target_dir = getwd(),
  material_dir = getOption("minutemaker_context_material_dir", "documentation"),
  overwrite = getOption("minutemaker_overwrite_context", FALSE),
  strategy = getOption("minutemaker_context_gen_strategy", "one_pass"),
  generate_expected_agenda = TRUE,
  generate_event_description = TRUE,
  generate_audience = TRUE,
  generate_vocabulary = TRUE,
  generate_initial_prompt = TRUE,
  expected_agenda = NULL,
  event_description = NULL,
  audience = NULL,
  vocabulary = NULL,
  stt_initial_prompt = NULL,
  external_transcript = NULL,
  llm_provider = getOption("llmr_llm_provider"),
  ...
)
}
\arguments{
\item{target_dir}{A directory containing meeting materials and workflow
inputs.}

\item{material_dir}{Folder name (relative to \code{target_dir}) containing
documentation materials. Defaults to the
\code{minutemaker_context_material_dir} option or \code{"documentation"}.}

\item{overwrite}{Logical value indicating whether existing context files
should be overwritten. Defaults to the
\code{minutemaker_overwrite_context} option or \code{FALSE}.}

\item{strategy}{One of \code{one_pass} or \code{agentic}. \code{one_pass} uses a
single-agent generation flow that requests all outputs in one LLM call.
\code{agentic} runs a multi-agent pipeline that first drafts context from
documentation materials, then proposes transcript-driven edits in batches,
and finally consolidates everything into final context files written at
the end.}

\item{generate_expected_agenda}{Logical value indicating whether to generate
the expected agenda.}

\item{generate_event_description}{Logical value indicating whether to
generate the event description.}

\item{generate_audience}{Logical value indicating whether to generate the
audience description.}

\item{generate_vocabulary}{Logical value indicating whether to generate the
vocabulary list.}

\item{generate_initial_prompt}{Logical value indicating whether to generate
the speech-to-text initial prompt.}

\item{expected_agenda}{Optional pre-existing expected agenda content.}

\item{event_description}{Optional pre-existing event description.}

\item{audience}{Optional pre-existing audience description.}

\item{vocabulary}{Optional pre-existing vocabulary.}

\item{stt_initial_prompt}{Optional pre-existing initial prompt.}

\item{external_transcript}{Optional path to an external transcript file to
use as additional material.}

\item{llm_provider}{Optional provider passed to \code{llmR::prompt_llm}.}

\item{...}{Additional arguments passed to \code{llmR::prompt_llm}.}
}
\value{
A list containing generated context values.
}
\description{
This function scans documentation materials (and optional transcripts) to
generate agenda expectations, event description, audience, vocabulary, and
optional speech-to-text prompts. Generated context is cached in per-field
files under a \code{context} folder.
}
\details{
By default, the active llmR model (option \code{llmr_current_model}) is used.
To force a specific model for context generation, set the option
\code{minutemaker_context_gen_llm_model} to a registered llmR model label
(e.g., \code{"mm_gpt-4.1_azure"}).
}
\examples{
\dontrun{
generate_context(target_dir = "meeting_folder")
}

}
\seealso{
\code{speech_to_summary_workflow()}
}
