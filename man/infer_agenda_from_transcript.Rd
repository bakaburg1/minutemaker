% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/summarization.R
\name{infer_agenda_from_transcript}
\alias{infer_agenda_from_transcript}
\title{Infer the agenda from a transcript}
\usage{
infer_agenda_from_transcript(
  transcript,
  event_description = NULL,
  vocabulary = NULL,
  diarization_instructions = NULL,
  start_time = NULL,
  expected_agenda = NULL,
  window_size = 3600,
  output_file = NULL,
  ...
)
}
\arguments{
\item{transcript}{The transcript to be summarised. Can be a file path or a
data frame.}

\item{event_description}{A description of the event. Provide context about
the event.}

\item{vocabulary}{A character vector of specific vocabulary words, names,
definitions, to help the LLM recognise misspellings and abbreviations.}

\item{diarization_instructions}{Instructions for the diarization of the
transcript. Default is NULL. If provided, it will help the LLM in
recognizing the speakers in the transcript.}

\item{start_time}{The start time of the event in the HH:MM(:SS)( AM/PM)
format. Necessary to convert the agenda times from seconds to an easier to
read format.}

\item{expected_agenda}{The expected agenda of the event. A text description
of the expected agenda. If provided, the LLM will be asked to generate an
agenda that matches this description.}

\item{window_size}{The time window that will be taken into account when
inferring the agenda. Default is 2 hours. A larger window will increase the
accuracy of the agenda since it will provide context and will prevent to
have talks crossing the window boundaries; also decrease the chance of
having the LLM being over sensitive to small changes in topics, generating
too many small talks. However, a larger window will also require a larger
LLM context.}

\item{output_file}{An optional file to save the results to. Default is NULL,
i.e., the results are not saved to a file.}

\item{...}{Additional arguments passed to the \code{prompt_llm} function.
Keep in consideration that this function needs LLMs that manages long
context and that produce valid JSON outputs. The \code{force_json} argument is
used with OpenAI based LLM but it's not accepted by other LLMs; therefore
the user may need to edit the system prompts to ensure that the output is a
valid JSON.}
}
\value{
An agenda in the usual list format.
}
\description{
This function takes a transcript and various optional parameters, and uses an
LLM to generate an agenda.
}
